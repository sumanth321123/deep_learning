{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dd80552",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 143ms/step - loss: 0.6899 - accuracy: 0.5447 - val_loss: 0.6709 - val_accuracy: 0.7442\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6684 - accuracy: 0.6974 - val_loss: 0.6513 - val_accuracy: 0.8140\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6506 - accuracy: 0.7368 - val_loss: 0.6329 - val_accuracy: 0.8140\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6321 - accuracy: 0.7789 - val_loss: 0.6143 - val_accuracy: 0.8372\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6134 - accuracy: 0.7974 - val_loss: 0.5967 - val_accuracy: 0.8140\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5988 - accuracy: 0.8026 - val_loss: 0.5802 - val_accuracy: 0.8140\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.8000 - val_loss: 0.5622 - val_accuracy: 0.8140\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.7974 - val_loss: 0.5471 - val_accuracy: 0.8140\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5470 - accuracy: 0.8132 - val_loss: 0.5307 - val_accuracy: 0.8140\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.5367 - accuracy: 0.8079 - val_loss: 0.5160 - val_accuracy: 0.8140\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.5203 - accuracy: 0.8105 - val_loss: 0.5019 - val_accuracy: 0.8140\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.5074 - accuracy: 0.8184 - val_loss: 0.4926 - val_accuracy: 0.8140\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.5005 - accuracy: 0.8132 - val_loss: 0.4825 - val_accuracy: 0.8140\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4923 - accuracy: 0.8079 - val_loss: 0.4742 - val_accuracy: 0.8140\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4822 - accuracy: 0.8132 - val_loss: 0.4698 - val_accuracy: 0.8140\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.8105 - val_loss: 0.4640 - val_accuracy: 0.8140\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4682 - accuracy: 0.8158 - val_loss: 0.4621 - val_accuracy: 0.8140\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4722 - accuracy: 0.8132 - val_loss: 0.4602 - val_accuracy: 0.8140\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4641 - accuracy: 0.8158 - val_loss: 0.4596 - val_accuracy: 0.8140\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4598 - accuracy: 0.8132 - val_loss: 0.4583 - val_accuracy: 0.8140\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4620 - accuracy: 0.8132 - val_loss: 0.4585 - val_accuracy: 0.8140\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4587 - accuracy: 0.8132 - val_loss: 0.4584 - val_accuracy: 0.8140\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4504 - accuracy: 0.8158 - val_loss: 0.4594 - val_accuracy: 0.8140\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4568 - accuracy: 0.8132 - val_loss: 0.4611 - val_accuracy: 0.8140\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4467 - accuracy: 0.8237 - val_loss: 0.4626 - val_accuracy: 0.8140\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4468 - accuracy: 0.8158 - val_loss: 0.4655 - val_accuracy: 0.8140\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.8158 - val_loss: 0.4660 - val_accuracy: 0.8140\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.4474 - accuracy: 0.8158 - val_loss: 0.4682 - val_accuracy: 0.8140\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4489 - accuracy: 0.8211 - val_loss: 0.4694 - val_accuracy: 0.8140\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.8184 - val_loss: 0.4700 - val_accuracy: 0.8140\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.8184 - val_loss: 0.4731 - val_accuracy: 0.8372\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.4736 - val_accuracy: 0.8372\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4385 - accuracy: 0.8237 - val_loss: 0.4759 - val_accuracy: 0.8372\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.4785 - val_accuracy: 0.8372\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8184 - val_loss: 0.4798 - val_accuracy: 0.8372\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4371 - accuracy: 0.8211 - val_loss: 0.4802 - val_accuracy: 0.8372\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4341 - accuracy: 0.8211 - val_loss: 0.4824 - val_accuracy: 0.8372\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4438 - accuracy: 0.8184 - val_loss: 0.4864 - val_accuracy: 0.8372\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4291 - accuracy: 0.8211 - val_loss: 0.4870 - val_accuracy: 0.8372\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.8237 - val_loss: 0.4888 - val_accuracy: 0.8372\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.8211 - val_loss: 0.4913 - val_accuracy: 0.8372\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4280 - accuracy: 0.8237 - val_loss: 0.4922 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4276 - accuracy: 0.8211 - val_loss: 0.4935 - val_accuracy: 0.8372\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.8158 - val_loss: 0.4948 - val_accuracy: 0.8372\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4306 - accuracy: 0.8184 - val_loss: 0.4962 - val_accuracy: 0.8372\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.8237 - val_loss: 0.4973 - val_accuracy: 0.8372\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4236 - accuracy: 0.8237 - val_loss: 0.4995 - val_accuracy: 0.8140\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4211 - accuracy: 0.8263 - val_loss: 0.5001 - val_accuracy: 0.8140\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4223 - accuracy: 0.8211 - val_loss: 0.5030 - val_accuracy: 0.8140\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4171 - accuracy: 0.8263 - val_loss: 0.5021 - val_accuracy: 0.8140\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8491\n",
      "Test Accuracy: 0.849056601524353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "data = pd.read_csv('Loan_data.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "data['Married'] = label_encoder.fit_transform(data['Married'])\n",
    "data['Education'] = label_encoder.fit_transform(data['Education'])\n",
    "data['Self_Employed'] = label_encoder.fit_transform(data['Self_Employed'])\n",
    "data['Property_Area'] = label_encoder.fit_transform(data['Property_Area'])\n",
    "data['Loan_Status'] = label_encoder.fit_transform(data['Loan_Status'])\n",
    "one_hot_cols = ['Dependents']\n",
    "for col in one_hot_cols:\n",
    "    one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_cols = pd.DataFrame(one_hot_encoder.fit_transform(data[[col]]))\n",
    "    encoded_cols.columns = [f'{col}_{i}' for i in range(encoded_cols.shape[1])]\n",
    "    data = pd.concat([data, encoded_cols], axis=1)\n",
    "    data.drop(columns=[col], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "X = data.drop(columns=['Loan_ID', 'Loan_Status'])\n",
    "y = data['Loan_Status']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "model = Sequential([\n",
    "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
